{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Review of AlphaGo algorithm by Google DeepMind**  \n",
    "by Fernando Martinelli Ramacciotti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of paper goals and techiniques**\n",
    "\n",
    "The board Go is viewed as the most challenging board games to be tackled by artificial intelligence. Since the search space is enourmous, it is unfeasible to train traditional search algorithms to build a game-playing agent. Instead, such artificial agent must, somehow, reduce the search space and intelligently evaluate board positions, without compromising performance.\n",
    "\n",
    "The novel framework proposed by Google DeepMind [1], the AlphaGo, combines several techniques that to predict and estimate of current and future moves and, therefore, is feasible to be deployed at runtime. The team come up with a pipeline of techniques that takes advantage of human expertise as well as self-play simulations evaluated by machine learning techniques.\n",
    "\n",
    "The pipeline consists of a Supervised Learning (SL) policy network, taken from expert human moves. Such step provides fast and efficient learning to begin. Afterwards, a Reinforcement Learning (RL) policy is trained to update the results from the SL policy, maximizing it towards winnings of games of self-play. This policy network combined outputs a probability distribution over legal moves at the current state. A value network is then trained by regression to predict the value of each position, i.e. whether the current player wins, from games of self-play of the RL network. A Monte Carlo Tree Search (MCTS) effectively evaluates the value of each position in the tree and outputs the most promising one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlphaGo outperformed other Go programs 99.8% of the time and defeated, for the first time, the European Go champion by 5 games to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Silver, David, et al. \"Mastering the game of Go with deep neural networks and tree search.\" nature 529.7587 (2016): 484."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
